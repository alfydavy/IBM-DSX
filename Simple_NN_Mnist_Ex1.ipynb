{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "60000 train samples\n10000 test samples\n"
                }
            ], 
            "source": "'''Trains a simple deep NN on the MNIST dataset.\n\nGets to 98.40% test accuracy after 20 epochs\n(there is *a lot* of margin for parameter tuning).\n2 seconds per epoch on a K520 GPU.\n'''\n\nfrom __future__ import print_function\n\nimport keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.optimizers import RMSprop\nfrom keras.layers import Conv2D, MaxPooling2D\n\nbatch_size = 128\nnum_classes = 10\nepochs = 20\nnum_classes = 10\nepochs = 20\n\n# the data, shuffled and split between train and test sets\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(60000, 784)\nx_test = x_test.reshape(10000, 784)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)\n"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 669,706\nTrainable params: 669,706\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "#Please construct the following neural network and report accuracy after training\n#Layer 1: 2D Convolution with 32 hidden neurons, kernel 3 by 3, relu activation, input_shape (28,28,1)\n#Layer 2: 2D MaxPooling, pool_size 2 by 2\n#Layer 3: Flatten (Hint: model.add(Flatten()))\n#Layer 4 Softmax Output Layer according to the problem (output vector)\n\n\n\nmodel = Sequential()\nmodel.add(Dense(512, activation='relu', input_shape=(784,)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(),\n              metrics=['accuracy'])"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/20\n60000/60000 [==============================] - 15s - loss: 0.8792 - acc: 0.7793 - val_loss: 0.3486 - val_acc: 0.8997\nEpoch 2/20\n60000/60000 [==============================] - 15s - loss: 0.7016 - acc: 0.8457 - val_loss: 0.4015 - val_acc: 0.9195\nEpoch 3/20\n60000/60000 [==============================] - 16s - loss: 1.4328 - acc: 0.8361 - val_loss: 1.3807 - val_acc: 0.8760\nEpoch 4/20\n60000/60000 [==============================] - 15s - loss: 2.6027 - acc: 0.8088 - val_loss: 2.5648 - val_acc: 0.8248\nEpoch 5/20\n60000/60000 [==============================] - 15s - loss: 3.3196 - acc: 0.7799 - val_loss: 4.3630 - val_acc: 0.7162\nEpoch 6/20\n60000/60000 [==============================] - 15s - loss: 3.6780 - acc: 0.7629 - val_loss: 5.2863 - val_acc: 0.6622\nEpoch 7/20\n60000/60000 [==============================] - 15s - loss: 4.2410 - acc: 0.7309 - val_loss: 3.7289 - val_acc: 0.7637\nEpoch 8/20\n60000/60000 [==============================] - 15s - loss: 4.8315 - acc: 0.6965 - val_loss: 5.1115 - val_acc: 0.6813\nEpoch 9/20\n60000/60000 [==============================] - 15s - loss: 5.7503 - acc: 0.6409 - val_loss: 5.8009 - val_acc: 0.6382\nEpoch 10/20\n60000/60000 [==============================] - 15s - loss: 5.6601 - acc: 0.6471 - val_loss: 4.4724 - val_acc: 0.7212\nEpoch 11/20\n60000/60000 [==============================] - 15s - loss: 5.7041 - acc: 0.6444 - val_loss: 4.5759 - val_acc: 0.7153\nEpoch 12/20\n60000/60000 [==============================] - 15s - loss: 5.7588 - acc: 0.6413 - val_loss: 4.5511 - val_acc: 0.7169\nEpoch 13/20\n60000/60000 [==============================] - 15s - loss: 5.7647 - acc: 0.6409 - val_loss: 5.3929 - val_acc: 0.6640\nEpoch 14/20\n60000/60000 [==============================] - 15s - loss: 5.7569 - acc: 0.6419 - val_loss: 5.6567 - val_acc: 0.6477\nEpoch 15/20\n60000/60000 [==============================] - 15s - loss: 5.6705 - acc: 0.6469 - val_loss: 5.5681 - val_acc: 0.6537\nEpoch 16/20\n60000/60000 [==============================] - 15s - loss: 5.9344 - acc: 0.6308 - val_loss: 5.1578 - val_acc: 0.6788\nEpoch 17/20\n60000/60000 [==============================] - 15s - loss: 5.9640 - acc: 0.6292 - val_loss: 5.3052 - val_acc: 0.6702\nEpoch 18/20\n60000/60000 [==============================] - 15s - loss: 5.7420 - acc: 0.6428 - val_loss: 5.0630 - val_acc: 0.6846\nEpoch 19/20\n60000/60000 [==============================] - 15s - loss: 5.9198 - acc: 0.6320 - val_loss: 5.1974 - val_acc: 0.6770\nEpoch 20/20\n60000/60000 [==============================] - 15s - loss: 5.7494 - acc: 0.6424 - val_loss: 5.3824 - val_acc: 0.6652\nTest loss: 5.38241677094\nTest accuracy: 0.6652\n"
                }
            ], 
            "source": "#some learners constantly reported 502 errors in Watson Studio. \n#This is due to the limited resources in the free tier and the heavy resource consumption of Keras.\n#This is a workaround to limit resource consumption\n\nfrom keras import backend as K\n\nK.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)))\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(x_test, y_test))\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}