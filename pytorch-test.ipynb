{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Introduction to PyTorch\n\nPyTorch's tensor library\nThe most of PyTorch operations are running on tensors. A tensor is an multidimensional array. Lets have a look on some basic tensor operations. But first, lets import some important PyTorch libraries:\n\ntorch - a Tensor library similar to NumPy, with strong GPU support\ntorch.autograd - a \"tape-based\" (about this - later on) automatic differentiation library\ntorch.nn - a neural networks library deeply integrated with autograd\ntorch.optim - an optimization package to be used with torch.nn with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.\nWe also set a seed to be able to reproduce the same results later.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "%matplotlib inline"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting torch==0.3.1 from http://download.pytorch.org/whl/cpu/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl\n  Downloading http://download.pytorch.org/whl/cpu/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl (47.2MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47.2MB 23.7MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/src/bluemix_jupyter_bundle.v80/notebook/lib/python2.7/site-packages (from torch==0.3.1)\nRequirement already satisfied: numpy in /gpfs/global_fs01/cluster/yp-spark-lon02-env5-0101.bluemix.net/user/sc40-7a5a3a293ff8f2-921461488860/.local/lib/python2.7/site-packages (from torch==0.3.1)\nInstalling collected packages: torch\nSuccessfully installed torch-0.3.1\nCollecting torchvision\n  Downloading torchvision-0.2.0-py2.py3-none-any.whl (48kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51kB 2.3MB/s ta 0:00:011\n\u001b[?25hRequirement already satisfied: six in /gpfs/global_fs01/cluster/yp-spark-lon02-env5-0101.bluemix.net/user/sc40-7a5a3a293ff8f2-921461488860/.local/lib/python2.7/site-packages (from torchvision)\nRequirement already satisfied: numpy in /gpfs/global_fs01/cluster/yp-spark-lon02-env5-0101.bluemix.net/user/sc40-7a5a3a293ff8f2-921461488860/.local/lib/python2.7/site-packages (from torchvision)\nRequirement already satisfied: torch in /gpfs/global_fs01/cluster/yp-spark-lon02-env5-0101.bluemix.net/user/sc40-7a5a3a293ff8f2-921461488860/.local/lib/python2.7/site-packages (from torchvision)\nRequirement already satisfied: pillow>=4.1.1 in /gpfs/global_fs01/cluster/yp-spark-lon02-env5-0101.bluemix.net/user/sc40-7a5a3a293ff8f2-921461488860/.local/lib/python2.7/site-packages (from torchvision)\nRequirement already satisfied: pyyaml in /usr/local/src/bluemix_jupyter_bundle.v80/notebook/lib/python2.7/site-packages (from torch->torchvision)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.2.0\n"
                }
            ], 
            "source": "!pip install http://download.pytorch.org/whl/cpu/torch-0.3.1-cp27-cp27mu-linux_x86_64.whl \n!pip install torchvision"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 2, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7fe935760350>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\n\ntorch.manual_seed(123)"
        }, 
        {
            "source": "### Creating Tensors", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<type 'list'>\n\n 1\n 2\n 3\n[torch.FloatTensor of size 3]\n\n\n 1  2  3\n 4  5  6\n[torch.FloatTensor of size 2x3]\n\n\n(0 ,.,.) = \n   1   2   3\n   4   5   6\n   7   8   9\n\n(1 ,.,.) = \n  10  11  12\n  13  14  15\n  16  17  18\n\n(2 ,.,.) = \n  19  20  21\n  22  23  24\n  25  26  27\n[torch.FloatTensor of size 3x3x3]\n\n\n(0 ,0 ,.,.) = \n -0.1115  0.1204 -0.3696\n -0.2404 -1.1969  0.2093\n -0.9724 -0.7550  0.3239\n\n(0 ,1 ,.,.) = \n -0.1085  0.2103 -0.3908\n  0.2350  0.6653  0.3528\n  0.9728 -0.0386 -0.8861\n\n(0 ,2 ,.,.) = \n -0.4709 -0.4269 -0.0283\n  1.4220 -0.3886 -0.8903\n -0.9601 -0.4087  1.0764\n\n(1 ,0 ,.,.) = \n -0.4015 -0.7291 -0.1218\n -0.4796 -0.5166 -0.3107\n  0.2057  0.9657  0.7057\n\n(1 ,1 ,.,.) = \n  0.7290  1.2775 -1.0815\n -1.3027  1.0827 -1.3841\n  0.4033 -1.2239  0.7017\n\n(1 ,2 ,.,.) = \n  2.2139 -0.0276  1.0541\n  0.5661 -0.3820  0.8807\n  0.2710  0.7694  0.3453\n\n(2 ,0 ,.,.) = \n  1.8979 -0.2357  0.7885\n  0.3208  0.8456 -0.3621\n  0.1027 -3.5310  0.5485\n\n(2 ,1 ,.,.) = \n -1.6063  0.7281  0.6609\n  0.2391  0.0340  0.1164\n -0.9905  0.5646  0.0686\n\n(2 ,2 ,.,.) = \n -1.0035 -0.7874  0.9840\n  0.2045 -0.3604  1.2101\n -1.0814  0.0789  0.2913\n\n(3 ,0 ,.,.) = \n -0.5023 -0.9306  0.9086\n -0.7788 -1.4453  0.7636\n -0.2469  0.5857  0.9906\n\n(3 ,1 ,.,.) = \n  0.0417 -1.1668  1.3251\n -0.7990  0.6292 -1.2097\n -2.1362 -0.1212 -0.1443\n\n(3 ,2 ,.,.) = \n  0.9969  0.5697 -0.4930\n  0.3155 -0.2275 -1.7942\n  1.0417 -0.2358 -0.3030\n[torch.FloatTensor of size 4x3x3x3]\n\n"
                }
            ], 
            "source": "# Create a torch.Tensor object from python list\nv = [1, 2, 3]\nprint(type(v))\nv_tensor = torch.Tensor(v)\nprint(v_tensor)\n\n# Create a torch.Tensor object of size 2x3 from 2x3 matrix\nm2x3 = [[1, 2, 3], [4, 5, 6]]\nm2x3_tensor = torch.Tensor(m2x3)\nprint(m2x3_tensor)\n\n# Create a 3D torch.Tensor object of size 3x3x3.\nm3x3x3 = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n          [[10, 11, 12],[13, 14, 15], [16, 17, 18]],\n            [[19, 20, 21],[22, 23, 24], [25, 26, 27]]]\nm3x3x3_tensor = torch.Tensor(m3x3x3)\nprint(m3x3x3_tensor)\n\n#Create a 4Dtensor from random data and given dimensions (in this case 3x4x5x6) with torch.randn()\nm4x3x3x3_tensor = torch.randn((4, 3, 3, 3))\nm4x3x3x3_tensor.shape\nprint(m4x3x3x3_tensor)"
        }, 
        {
            "source": "### What is a multidimensional tensor?\n\nSince we frequently deal with n > 3 dimensional tensors, its understanding is very important. The best way to think of a higher (n) dimensional object (and tensor in particular) is as of a container which keeps a series of n-1 dimensional objects \"inside\" of it. We can \"pull out\" these \"inner\" objects by indexing in to higher dimensional tensor container. Let's have a look on some examples:\n\nFor a vector v (dim(v)=1), indexing into it (\"pulling out of it\") returns its \"slice\" - a scalar s (dim(s)=0).\n\nFor a matrix, indexing into it returns its \"slice\" - a (row or column) vector.\n\n3D tensor can be seen as a cube or 3D rectangular consisting of horizontally \"stacked\" matrices. So if we index into a such tensor it will give us its slice which is a matrix!\n\nWe can't easily visualize 5D (or n-D) tensors, but the idea is actually the same. If we index in to them, we will pull out an object of dimension n-1.\n\nE.g. a 4D tensor can be seen as a list of cubes or 3D reactangulars. If we index in to a 4D tensor, we will get 3D rectangulars.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}